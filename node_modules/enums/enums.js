// UNCLASSIFIED 

/**
Provides basic data enumerators.

@module ENUMS

@requires os
@requires cluster
@requires fs
@requires http
@requires https
@requires vm
*/

/**
Extend the con prototype with the specified methods.  Array, String, Date, and Object keys are 
interpretted to extend their respective prototypes.  
@memberof Array
*/
Array.prototype.Extend = function (con) {
	this.forEach( function (proto) {
		//console.log("ext", proto.name, con);
		con.prototype[proto.name] = proto;
	});
}

const
	ENV = process.env,
	OS = require("os"),
	FS = require("fs"),
	STREAM = require("stream"),
	HTTP = require("http"),						//< http interface
	HTTPS = require("https"),					//< https interface	  
	CLUSTER = require("cluster"),
	VM = require("vm");

// enum i/f

/**
Create a clock object with specified trace switch, every interval, on-off times, and start date.
See the clock tick method for more information.

@param {Boolean} trace tracking switch
@param {String | Float} every tick interval
@param {Float} on on-time or 0 implies infinity
@param {Float} off off-time or 0
@param {Date} start start date

*/

function Clock(trace,every,on,off,start) {
	this.next = start ? new Date( start ) : new Date();
	this.on = on || Infinity;
	this.off = off || 0;
	this.epoch = this.off;
	this.every = every;
	this.trace = trace;
	this.cycle = off ? on+off-2 : 1; //(on>=2) ? on+off-2 : 0;  // Internal clock cycle = CYCLE - 2 = ON+OFF-2.
	this.step = 1;
	this.util = on ? on/(on+off) : 0;
	
	if ( trace ) Log(this);
}

const
	{ 	
		operators,
		Copy, Each, typeOf, Stream, Log,
	 	isArray, isObject, isString, isFunction } = ENUM = module.exports = {
	
	Log: (...args) => console.log(">>>enum", args),

	config: opts => {
		if ( opts ) Copy( opts, ENUM, "." );
	},
	
	typeOf: obj => obj.constructor.name,
	isString: obj => typeOf(obj) == "String",
	isNumber: obj => typeOf(obj)== "Number",
	isArray: obj => typeOf(obj) == "Array",
	isKeyed: obj => Object.keys(obj).length ? true : false,
	isObject: obj => typeOf(obj) == "Object",
	isDate: obj => typeOf(obj) == "Date",
	isFunction: obj => typeOf(obj) == "Function",
	isError: obj => typeOf(obj) == "Error",
	isBoolean: obj => typeOf(obj) == "Boolean",
	isBuffer: obj => typeOf(obj) == "Buffer",
	isEmpty: opts => {
		for ( var key in opts ) return false;
		return true;
	},
	
/**
Defines parsePath operators.
*/
	operators: ["=", "<", "<=", ">", ">=", "!=", "!bin=", "!exp=", "!nlp="],

/**
Copy source hash src to target hash tar.  If the copy is shallow (deep = false), a 
Copy({...}, {}) is equivalent to new Object({...}).  In a deep copy,
(e.g. deep = "."), src keys are treated as keys into the target thusly:

	{	
		A: value,			// sets target[A] = value

		"A.B.C": value, 	// sets target[A][B][C] = value

		"A.B.C.": {			// appends X,Y to target[A][B][C]
			X:value, Y:value, ...
		},	

		OBJECT: [ 			// prototype OBJECT (Array,String,Date,Object) = method X,Y, ...
			function X() {}, 
			function Y() {}, 
		... ]

	} 

@param {Object} src source hash
@param {Object} tar target hash
@param {String} deep copy key 
@return {Object} target hash
*/
	Copy: (src,tar,deep) => {

		for (var key in src) {
			var val = src[key];

			if (deep) 
				switch (key) {
					case Array: 
						val.Extend(Array);
						break;

					case "String": 
						val.Extend(String);
						break;

					case "Date": 
						val.Extend(Date);
						break;

					case "Object": 	
						val.Extend(Object);
						break;

					/*case "Function": 
						this.callStack.push( val ); 
						break; */

					default:

						var 
							keys = key.split(deep), 
							Tar = tar,
							idx = keys[0],
							N = keys.length-1;

						for ( var n=0; n < N ;  idx = keys[++n]	) { // index to the element to set/append
							if ( idx in Tar ) {
								if ( !Tar[idx] ) Tar[idx] = new Object();
								Tar = Tar[idx];
							}

							else
								Tar = Tar[idx] = new Object(); //new Array();
						}

						if (idx)  // not null so update target
							Tar[idx] = val;

						else  // null so append to target
						if (val.constructor == Object) 
							for (var n in val) 
								Tar[n] = val[n];

						else
							Tar.push( val );
				}

			else
				tar[key] = val;
		}

		return tar;
	},

/**	 
Enumerate Object A over its keys with callback cb(key,val).

@param {Object} A source object
@param {Function} cb callback (key,val) 
*/
	Each: ( A, cb ) => {
		Object.keys(A).forEach( key => cb( key, A[key] ) );
	},
	
/**	 
Stream Array|Object|File src to callback where:

	cb( (rec,key,res) => {
		if ( res ) // still streaming 
			res( msg || undefined )  // pass undefined to bypass msg stacking

		else 
			// streaming done so key contains msg stack
	})

@param {Object | Array | String} src source object or array
@param {Function} cb callback ( rec || null, key, res ) 		
*/
	Stream: (src,opts,cb) => {
		
		var
			msgs = []; 
		
		if ( isString(src) ) 	// stream file
			src.streamFile( opts, recs => {
				if ( recs )
					recs.forEach( (rec,idx) => {
						cb( rec, idx, msg => {
							if ( msg != undefined ) 
								msgs.push( msg );
						});
					});
				
				else	// signal end
					cb(null, msgs);
			});
		
		else {	// stream array/object
			var 
				returns = 0, 
				calls = src.forEach ? src.length : Object.keys(src).length;

			Each( src, (key, rec) => {
				cb( rec, key, msg => {
					if ( msg != undefined ) 
						msgs.push( msg );
						/*
						if ( A.forEach ) 
							msgs.push( msg );
						else
							msgs[key] = msg;
						*/

					if ( ++returns == calls ) // signal end
						cb( null, msgs );
				});
			});

			if ( !calls ) cb( null, msgs );
		}
	},
			
	Clock: Clock
};

[
	function now() {
		return new Date( this.next );
	},
	
/**
Return the wait time to next event, with callback(wait,next) when at snapshot events.

Example below for ON = 4 and OFF = 3 steps of length vlock.every.

Here S|B|* indicates the end of snapshot|batch|start events.  The clock starts on epoch = OFF 
with a wait = 0.  The clock's host has 1 step to complete its batch tasks, and OFF steps to 
complete its snapshot tasks.  Here, the work CYCLE = ON+OFF with a utilization = ON/CYCLE.  
Use OFF = 0 to create a continious process.  

		S			*	B	B	B	S			*	B	B	B
		|			|	|	|	|	|			|	|	|	|		...
		|			|	|	|	|	|			|	|	|	|		
		x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x-->x
epoch	0	1	2	3	4	5	6	7	8	9	10	11	12	13	14	15	16	17

		|<-- OFF -->|<---- ON ----->|
*/
	
	function tick(cb) {		// advance clock, return waitTime, and callback cb(nextTime) on state-change epochs 
		
		const
			{ max,trunc } = Math,
			{ step,every,on,off,epoch,trace,next,start,cycle } = this,
			now = new Date(),
			wait = max( 1e3, next.getTime() - now.getTime() );

		if (trace)
			Log( `e=${epoch} s=${step} w=${trunc(wait)} n=${next}` );

		if ( cycle > 1 )	// using on-off process
			if ( epoch % cycle == 0 ) {
				this.step = off;
				if (trace)
					Log( `e=${epoch} s=${step} w=${trunc(wait)} n=${next}` );
				if (cb) cb( wait, next );
			}
		
			else			// continious process
				this.step = 1;
		
		this.epoch += this.step;
		
		switch ( every ) {		// advance next job epoch
			case "yr":
			case "year": 	next.setFullYear( next.getFullYear() + this.step ); break;
			case "wk":
			case "week": 	next.setDate( next.getDate() + 7*this.step ); break;
			case "day": 	next.setDate( next.getDate() + this.step ); break;
			case "hr":
			case "hour": 	next.setHours( next.getHours() + this.step ); break;
			case "min":
			case "minute": 	next.setMinutes( next.getMinutes() + this.step ); break;
			case "sec":
			case "second": 	next.setSeconds( next.getSeconds() + this.step ); break;

			case "monday": 
			case "tuesday":
			case "wednesday":
			case "thursday":
			case "friday":
			case "saturday":
			case "sunday":
			case "mon":
			case "tue":
			case "wed":
			case "thr":
			case "fri":
			case "sat":
			case "sun":
				next.setDate( next.getDate() + 7 - next.getDay() + 1); 
				this.every = "week";	// now switch to weeks
				// Log(">>>>>clock next", this.next, this.every);
				break;
				
			default:
				next.setTime( next.getTime() + every*1e3 );

		}

		return wait;
	}
].Extend(Clock);

[	
/**
Serialize this Array to the callback cb(rec,info) or cb(null,stack) at end given 
a sync/async fetcher( rec, res ).
*/
	function serialize(fetcher, cb) {
		Stream( this, {}, (rec, key, res) => {
			if ( res )
				fetcher( rec, info => {
					cb(rec, info);	// forward results
					res();	// signal record processed w/o stacking any results
				});	
			
			else 
				cb( null, res );
		});
	},
	
	function any( cb ) {
		var test = false;
		if ( cb )
			if ( typeof cb == "function" )
				this.forEach( val => {
					if ( cb(val) ) test = true;
				});
		
			else
				this.forEach( val => {
					if ( val == cb ) test = true;
				});
				
		else
			this.forEach( val => {
				if ( val ) test = true;
			});
			
		return test;
	},
	
	function all( cb ) {
		var test = true;
		if ( cb )
			if ( typeof cb == "function" )
				this.forEach( val => {
					if ( !cb(val) ) test = false;
				});
		
			else
				this.forEach( val => {
					if ( val != cb ) test = false;
				});
				
		else
			this.forEach( val => {
				if ( !val ) test = false;
			});
			
		return test;
	},
	
/**
Get elements or records using a keyList "OPTION, ..." || "[KEY,...]" || "!shuffle" where 

	OPTION = [ SRCKEY || !rem || REGEXP || (JS) ] => [ TARKEY || !test ] || INDEX 
	REGEXP is any regular expression to match source record keys, 
	JS evaluates the script in the source record context, 
	INDEX is a record index to return, 
	!rem matches all remaining source keys, 
	!test accepts the record if its SRC is true, 
	!shuffle is a random permutation.

Pass a stash to store indexing variables.  Add an optional $ctx to the stash to define functions and variables
available to JS scripts.

@example

	[{a1:10,a2:0,b:20,c1:4,c2:"there"},{a1:11,a2:111,b:21,c1:5,c2:"hello"}].get("1,0,0", {} )
	>> [
	  { a1: 11, a2: 111, b: 21, c1: 5, c2: 'hello' },
	  { a1: 10, a2: 0, b: 20, c1: 4, c2: 'there' },
	  { a1: 10, a2: 0, b: 20, c1: 4, c2: 'there' }
	  ]

@example

	[{a1:10,a2:0,b:20,c1:4,c2:"there"},{a1:11,a2:111,b:21,c1:5,c2:"hello"}].get("b=>B,(a1+a2-10)=>!test,(a1+a2)=>C,!rem=>D", {} )
	>> [
	  {
		B: 21,
		'!test': 112,
		C: 122,
		D: { a1: 11, a2: 111, b: 21, c1: 5, c2: 'hello' }
	  }
	]

@example

	[{a1:10,a2:0,b:20,c1:4,c2:"there"},{a1:11,a2:111,b:21,c1:5,c2:"hello"}].get("[a1,a2]")
	>> [ [ 10, 0 ], [ 11, 111 ] ]

	[{a1:10,a2:0,b:20,c1:4,c2:"there"},{a1:11,a2:111,b:21,c1:5,c2:"hello"}].get("[a1]")
	>> [ [ 10 ], [ 11 ] ]

	[[1,2,3,4],[5,6,7,8]].get("[0]")
	>> [ [ 1 ], [ 5 ] ]
*/
	function get(keyList, stash) {
		
		const
			recs = this,
			rec0 = recs[0] || {},
			Recs = [],
			stashKeys = Object.keys(stash);
		var
			{ $index,$ctx } = stash;
		
		if ( keyList ) 
			if ( keyList.charAt(0) == "[" ) {
				recs.forEach ( rec => {
					var Rec = [];
					Recs.push( Rec );
					keyList.substr(1,keyList.length-2).split(",").forEach( key => Rec.push( rec[key] ) );					
				});
				return Recs;
			}
		
			else
				switch (keyList) {
					case "!shuffle":
						return Recs;
						break;

					default: 
						if ( ! $index ) {
							$index = stash["$index"] = [];

							keyList.split(",").forEach( key => {
								var idx = parseInt(key);

								//Log(key,idx,idx !== NaN);
								if ( isNaN(idx) ) {
									const 
										[srcKey,tarKey0] = key.split("=>"),
										tarKey = tarKey0 || srcKey;

									if ( tarKey in stash ) {
									}

									else
									switch (srcKey) {
										case "!rem":
										case "!":
											for ( var SrcKey in rec0 ) {
												var
													inside = false;
												const 
													tar = stash[tarKey] || (stash[tarKey] = {});

												Each( stash, (tarKey, keys) => {
													if ( keys.any )
														if ( keys.any( key => key == SrcKey ) ) inside = true;

													else
													if ( keys == SrcKey ) inside = true;
												});
												if (!inside) tar[SrcKey] = SrcKey;
												//console.log(inside, stash, SrcKey, stash);
											}
											break;

										default:
											if ( srcKey.indexOf( "(" ) >= 0 ) 
												stash[tarKey] = ctx => {
													try {
														return VM.runInContext( srcKey.replace(/;/g,","), VM.createContext(Copy($ctx||{},ctx)));
													}
													catch (err) {
														return null;
													}						
												};

											else
											if ( srcKey in rec0 )
												stash[tarKey] = srcKey;

											else {
												const
													findKey = new RegExp(srcKey),
													srcKeys = stash[tarKey] = [];

												for ( var key in rec0 )
													if ( key ) 
														if ( key.match(findKey) )
															srcKeys.push( key );

												if ( srcKeys.length == 1 ) stash[tarKey] = srcKeys[0];
											}
									}
								}

								else
									$index.push( idx );
							});	
						}

						if ( $index.length ) 
							$index.forEach( idx => Recs.push( new Object( recs[idx] ) ));

						else
							recs.forEach( rec => {
								const
									Rec = {};
								var
									keep = true;

								for ( tarKey in stash ) if ( !tarKey.startsWith("$") ) {
									const
										srcKeys = stash[tarKey];
									var
										save;

									if ( srcKeys.forEach ) {
										save = Rec[tarKey] = [];
										srcKeys.forEach( srcKey => save.push( rec[ srcKey ] ) );	
									}

									else
									if ( typeof srcKeys == "function" ) 
										save = Rec[tarKey] = srcKeys( rec );

									else
									if ( srcKeys.length )
										save = Rec[tarKey]= rec[srcKeys];

									else {
										save = Rec[tarKey] = {};
										Each( srcKeys, (TarKey,SrcKey) => save[TarKey] = rec[SrcKey] );
									}

									switch (tarKey) {
										case "!test":
										case "!":
											if ( save.forEach ) {
												keep = save.all( v => v?true:false );
												delete Rec[tarKey];
											}

											else
												keep = save?true:false;

											break;

										default:
											Rec[tarKey] = save;
									}

								}

								if ( keep ) Recs.push( Rec );
							});

						return Recs;
				}
		
		else
			return recs;
	},
	
	function put( cb ) {
		const tar = this;
		this.forEach( (arg,i) => tar[i] = cb(arg,i) );
		return this;
	},
	
	function select(cb) {
		const rtn = [];
		this.forEach( (arg,i) => {
			if ( res = cb(arg,i) ) rtn.push(res);
		});
		return rtn;
	}
	
].Extend(Array);

[
	function replaceSync( pat, cb ) {
		var todo = 0, done=0, rtn = this+"";
		
		rtn = this.replace( pat, (...args) => {
			const hold = `@@hold${todo++}`;
			
			//console.log("hold", hold, todo, done);
			cb( args, res => {
				//console.log("res return(", rtn, ")=>", res, done, todo);
				rtn = rtn.replace( hold, res );
				
				if ( ++done == todo ) 
					cb( rtn ); 
			});
			return hold;
		});
			
		//console.log("rtn scanned", rtn);
		if ( !todo ) cb( rtn );
	},
	
/**
Tag url with specified attributes.

@memberof String
@param {String} el tag html element or one of "?&/:=" 
@param {String} at tag attributes = {key: val, ...}
@return {String} tagged results
*/ 
	function tag(el,at) {
		switch (el) {
			case "/":
			case "?":
			case "&":   // tag a url
				var rtn = this;

				Each(at, (key,val) => {
					if ( val ) {
						rtn += el + key + "=" + val;
						el = "&";
					}
				});

				return rtn;	

			case "[]":
			case "()":
				var rtn = this+el.substr(0,1), sep="";
				Each(at, (key,val) => {
					rtn += sep + key + ":" + JSON.stringify(val);
					sep = ",";
				});
				return rtn+el.substr(-1);
				
			case ":":
			case "=":
				var rtn = this, sep="";
				Each(at, (key,val) => {
					rtn += sep + key + el + JSON.stringify(val);
					sep = ",";
				});
				return rtn;

			case "":
				return `<a href="${el}">${this}</a>`;

			default: // tag html

				var rtn = "<"+el+" ";

				if ( at )
					Each( at, (key,val) => {
						if ( val )
							rtn += key + "='" + val + "' ";
					});

				switch (el) {
					case "embed":
					case "img":
					case "link":
					case "input":
						return rtn+">" + this;
					default:
						return rtn+">" + this + "</"+el+">";
				}
		}
	},

/**
Parse "$.KEY" || "$[INDEX]" expressions given $ hash.

@memberof String
@param {Object} $ source hash
*/
	function parseEval($) {
		try {
			return eval(this+"");
		}
		
		catch (err) {
			return err+"";
		}
	},
	
/**
Run JS against string in specified context.

@memberof String
@param {Object} ctx context hash
*/
	function parseJS(ctx, cb) {
		try {
			return VM.runInContext( this+"", VM.createContext(ctx || {}));
		}
		catch (err) {
			//Log("parseJS", this+"", err, ctx);
			if ( cb ) 
				return cb(err);
			
			else
				return null;
		}
	},
	
/**
Return an EMAC "...${...}..." string using supplied context.

@memberof String
@param {Object} query context hash
*/
	function parse$(ctx) {
		try {
			return VM.runInContext( "`" + this + "`" , VM.createContext(ctx));
		}
		catch (err) {
			return err+"";
		}
	},
	
/**
Parse string into json or set to default value/callback if invalid json.

@memberof String
@param {Function | Object} def default object or callback that returns default
*/
	function parseJSON(def) {
		try { 
			return JSON.parse(this);
		}
		catch (err) {  
			//Log("jparse", this, err);
			return def ? (isFunction(def) ? def(this+"") : def) || null : null;
		}
	},

/**
Parse a "PATH?PARM&PARM&..." url into the specified query, index, flags, or keys hash
as directed by the PARM = ASKEY := REL || REL || _FLAG = VALUE where 
REL = X OP X || X, X = KEY || KEY$[IDX] || KEY$.KEY and returns [path,file,type].

@memberof String
@param {Object} query hash of query keys
@param {Object} index hash of sql-ized indexing keys
@param {Object} flags hash of flag keys
@param {Object} where hash of sql-ized conditional keys
*/
	function parsePath(query,index,flags,where) { 
		var 
			search = this+"",
			ops = {
				equal: /(.*?)(:=|<=|>=|\!=|_=|\!bin=|\!exp=|\!nlp=)(.*)/,
				other: /(.*?)(<|>|=)(.*)/ 
			},
			[xp, path, search] = search.match(/(.*?)\?(.*)/) || ["",search,""],
			[xf, area, table, type] = path.match( /\/(.*?)\/(.*)\.(.*)/ ) || path.match( /\/(.*?)\/(.*)/ ) || path.match( /(.*)\/(.*)\.(.*)/ ) || path.match( /(.*)\/(.*)(.*)/ ) || ["","","",""];
			
		
		//Log(">>>>path", [search, path, search, area, table, type]);
		
		operators.forEach( key => where[key] = {} );
		
		search.split("&").forEach( parm => {
			if (parm) {
				const 
					[lhs,op,rhs] = parm.parseOP(ops.equal, parm => parm.parseOP( ops.other, parm => [parm,".",""] )),
					RHS = rhs.parseJSON( arg => arg ); 
				
				// Log(">>>search", [parm,lhs,rhs,op]);
				
				if (lhs)
				switch (op) {
					case "=":
						switch ( lead = lhs.charAt(0) ) {
							case "_":
								flags[lhs.substr(1)] = RHS;
								break;
								
							default:
								where["="][lhs] = rhs;
								query[lhs] = RHS;
						}
						break;

					case "_":
						flags[lhs] = RHS;
						break;
						
					case ".":
						index[lhs] = "";
						break;
						
					case ":=":
						index[lhs] = rhs;
						break;
						
					case "<":
					case ">":
					case "<=":
					case ">=":
					case "!=":
					case "!bin=":
					case "!exp=":
					case "!nlp=":
						where[op][lhs] = rhs;
						break;
				}
			}
		});
		
		return [path,table,type,area,search];
	},

	function parseURL(opts,base) {
		const 
			url = this+"",
			{username,password,hostname,protocol,pathname,search,port,href} = new URL(url,base);

		//Log(">>>>url", URL(url,base) );

		return Copy( opts || {}, {
			auth: username + ":" + password,
			path: pathname + search,
			protocol: protocol,
			host: hostname,
			port: port,
			href: href
		});
	},

/**
Chunk stream at path by splitting into newline-terminated records.
Callback cb(record) until the limit is reached (until eof when !limit)
with cb(null) at end.

@memberof String
@param {String} path source file
@param {Object} opts {newline,limit} options
@param {Function) cb Callback(record)
*/
	function chunkFile({newline,limit},cb) {
		const
			path = this+"";

		FS.open( path, "r", (err, fd) => {
			Log(">>>chunk", path, err, limit);
			
			if (err) 
				cb(null);	// signal pipe end

			else {	// start pipe stream
				var 
					pos = 0,
					rem = "",
					run = true,
					src = FS.createReadStream( "", { fd:fd, encoding: "utf8" }),
					sink = new STREAM.Writable({
						objectMode: true,
						write: (bufs,en,sinkcb) => {
							//Log( ">>>>chunk stream", limit,pos,!limit || pos<limit);
							if ( run ) {
								var 
									recs = (rem+bufs).split(newline);

								rem = recs.pop();

								if ( limit )	// chunk limited records
									recs.forEach( (rec,n) => {
										if ( rec ) 
											if ( pos<limit ) 
												cb(rec,pos++);
											else {
												//Log(">>>>chunk halting");
												run = false;
											}
										else
											pos++;
									});
								
								else	// chunk all records
									recs.forEach( (rec,n) => {
										if ( rec ) 
											cb(rec,pos++);
										else
											pos++;
									});									
							}
							sinkcb(null);  // signal no errors
						}
					});

				sink
					.on("finish", () => {	// signal complete
						//Log(">>>chunk finish", limit, pos);
						if (!limit || pos<limit)	// flush buffer
							if ( rem ) cb(rem,pos);
					
						cb(null);	// signal complete
					})
					.on("error", err => cb(null) );

				src.pipe(sink);  // start the pipe
			}
		});
	},

/**
Split stream at path containing comma delimited values: when keys = [],
the record keys are determined by the first header record; when keys = 
[ 'key', 'key', ...], then header keys are preset; when keys = null, 
raw text records are returned; when keys = parse(buf) function, then this
function used to parse (e.g.) json records.  The file is chunked using the (newline,
limit) chinkFile parameters.  Callsback cb(record) for each record with
cb(null) at end.

@memberof String
@param {String} path source file
@param {Object} opts {keys,comma,newline,limit} options
@param {Function} cb Callback(record || null)
*/
	function splitFile({keys, comma, newline, limit}, cb) {
		const
			path = this+"",
			opts = {newline:newline,limit:limit};
	
		var 
			pos = 0;
		
		if ( keys ) {		// split csv/json file
			const
				parse = keys.forEach 
					? (buf,keys) => {		// parse csv/txt buffer
						if ( keys.length ) {	/// at data row
							var 
								rec = {},
								cols = buf.split(comma);

							keys.forEach( (key,m) => rec[key] = cols[m] );
							return rec;
						}

						else {	// at header row so define keys
							if ( buf.charCodeAt(0) > 255 ) buf=buf.substr(1);	// weird
							buf.split(",").forEach( key => keys.push(key) );
							//Log(">>>split header keys", keys);
							return null;
						}
					}

					: buf => keys( {} );	// parse file buffer

			path.chunkFile( opts, buf => {			// get a record buffer
				if ( buf ) 
					if (rec = parse(buf,keys) ) 	// have data record
						cb(rec,pos++);
					else							// have empty record
						pos++;

				else	// forward eof signal 
					cb(null);
			});
		}
		
		else				// split txt file
			path.chunkFile( opts, buf => {
				if ( buf ) 
					cb(buf,pos++);

				else	// forward end signal 
					cb(null);
			});			
	},

/**
Filter stream at path containing comma delimited values.  The file is split using the (keys,comma) 
file splitting parameters, and chunked using the (newline,comma) file chunking parameters. Callsback 
cb([record,...]) with a record batch (all records when !batch) with cb(null) at end.  
Use the optional rekey = "fromKey=>toKey, regexp=>toKey, (js)=>toKey, !rem=>toKey, fromKey=>!test ..." 
to rekey records.

@memberof String
@param {String} path source file
@param {Object} opts {keys,comma,newline,limit,rekey,batch} options
@param {Function} cb Callback( [record,...] || null )
*/
	function streamFile({batch, keys, comma, newline, limit, rekey}, cb) {
		const 
			path = this+"",
			recs = [],
			opts = {keys:keys, limit:limit, comma:comma||",", newline:newline||"\n"},
			rekeyStash = {
				$ctx: {
					$tag: (str,el,tags) => str.tag(el,tags),
					$link: (str,ref) => str.tag("a",{href:ref}),
					$grab: str => str.replace(/.*\#(.*)\#.*/, (str,arg) => arg )
					//+ $.get(list,"[from || regexp || (JS) || !rem] => [to || !test] || INDEX, ..."  )  
					//+ $.resize(256,256)
					//+ $.greyscale()
					//+ $.sym( {maps:{x:'RGB',y:'L'}, limits:{cols:N,rows:N}, levels:{x:N,y:N}} )					
				}
			};
		
		var
			pos = 0;
		
		path.splitFile( opts, rec => {
			if ( rec ) 
				if ( !batch || recs.length<batch ) 
					recs.push( rec );

				else {	// flush batch
					cb( recs.get(rekey,rekeyStash), pos+=recs.length );
					recs.length = 0;
				}
					
			else { // forward end signal
				//Log("!!!!!!!!!!!!eos", recs.length);
				cb(recs.get(rekey,rekeyStash), pos+=recs.length); // flush batch
				//Log("!!!!!!!!!!!!eos end");
				cb(null);	// signal end
			}
		});
	},
	
/**
Log message to console with optional request to place into syslogs
@memberof String
@param {String} msg message to trace
@param {Object} req request { sql, query, client, action, table } 
@param {Function} res response callback(msg)
*/
	function trace(msg,req,res) {	
		function cpu() {
			var sum = 0, util = OS.loadavg();
			for ( var n=0, N = util.length; n<N; n++) sum += util[0];
			return sum / N;
		}
		
		function mem() {
			return OS.freemem() / OS.totalmem();
		}
		
		const
			node = CLUSTER.isMaster ? 0 : CLUSTER.worker.id,
			log = node + ">"  + this.toUpperCase() + ">" + msg;
		
		(res||console.log)( log );
		
		if ( req ) {
			const { sql, query, client, action, table } = req;
			
			if ( sql ) 
				sql.query( "INSERT INTO openv.syslogs SET ? ", {
					Node: OS.hostname()+"."+node,
					Client: client,
					Table: table,
					At: new Date(),
					Case: query.Name || "",
					Action: action,
					Module: this,
					cpuUtil: cpu(),
					memUtil: mem(),
					Message: msg+""
				});
		}
	},
		
/**
Serialize this String to the callback(results) given a sync/asyn fetcher(rec,res) where
rec = {ID, arg0, arg1, ...} contains args produced by regex.  Provide a unique placeholder
key to back-substitute results.

@memberof String
@example

	"junkabc;junkdef;"
	.serialize( (rec,cb) => cb("$"), /junk([^;]*);/g, "@tag", msg => console.log(msg) )

produces:

	"$$"
*/
	function serialize( fetcher, regex, key, cb ) {  //< callback cb(str) after replacing regex using fetcher( rec, (ex) => "replace" ) and string place holder key
		var 
			recs = [],
			results = this.replace( regex, (arg0, arg1, arg2, arg3, arg4) => {  // put in place-holders
				recs.push( {ID: recs.length, arg0:arg0, arg1:arg1, arg2:arg2, arg3:arg3, arg4:arg4} );
				return key+(recs.length-1);
			});

		recs.serialize( fetcher, (rec,info) => {  // update place-holders with info 
			if (rec) 
				results = results.replace( key+rec.ID, str => info );

			else 
				cb( results );
		});

	},
	
	/*function parseOP(reg, failcb, workcb) {
		var 
			[x,lhs,op,rhs] = this.match(reg) || [];

		return op ? workcb ? workcb(lhs,op,rhs) : [lhs, op, rhs] : failcb ? failcb(this+"") : null;
	}  */

	function parseOP(reg, cb) {
		var 
			[x,lhs,op,rhs] = this.match(reg) || [];

		return op ? [lhs,op,rhs] : cb(this+"");
	}
].Extend(String);

//================== Unit testing

switch (process.argv[2]) {	//< unit testers
	case "?":
		Log("unit test with 'npm enum.js [E1 || ...]'");
		break;
		
	case "E1": 
		Log({
			shallowCopy: Copy( {a:1,b:2}, {} ),
			deepCopy: Copy({ a:1,"b.x":2 }, {b:{x:100}}, ".")
		});
		break;
		
	case "X":
		"testabc; testdef;".replaceSync(/test(.*?);/g, (args,cb) => {
			
			if ( cb ) {
				console.log("args", args);
				cb( "#"+args[1] );
			}
			
			else
				console.log("final", args);
		});
}

// UNCLASSIFIED
